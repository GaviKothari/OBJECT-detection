{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "918287a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.2.75-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.32.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.4.0)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/subhash/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/subhash/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/subhash/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/subhash/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/subhash/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/subhash/anaconda3/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/subhash/anaconda3/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/subhash/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/subhash/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/subhash/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/subhash/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (69.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/subhash/anaconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.20)\n",
      "Requirement already satisfied: six>=1.5 in /home/subhash/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/subhash/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/subhash/anaconda3/lib/python3.12/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Using cached ultralytics-8.2.75-py3-none-any.whl (865 kB)\n",
      "Using cached torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl (7.0 MB)\n",
      "Using cached ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: ultralytics-thop, torchvision, ultralytics\n",
      "Successfully installed torchvision-0.19.0 ultralytics-8.2.75 ultralytics-thop-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc1e3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to convert in YOLO format\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Define paths\n",
    "image_folder = r'C:\\Users\\Subhash\\dataset\\OIDv4_ToolKit\\OID\\Dataset\\train\\Bottle_Plastic bag_Tin can\\images'\n",
    "label_folder = r'C:\\Users\\Subhash\\dataset\\OIDv4_ToolKit\\OID\\Dataset\\train\\Bottle_Plastic bag_Tin can\\Label'\n",
    "output_folder = r'C:\\Users\\Subhash\\dataset\\OIDv4_ToolKit\\OID\\Dataset\\train\\Bottle_Plastic bag_Tin can\\Label_yolo'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to convert bbox to YOLO format\n",
    "def convert_to_yolo(xmin, ymin, xmax, ymax, img_width, img_height):\n",
    "    x_center = (xmin + xmax) / 2.0 / img_width\n",
    "    y_center = (ymin + ymax) / 2.0 / img_height\n",
    "    width = (xmax - xmin) / img_width\n",
    "    height = (ymax - ymin) / img_height\n",
    "    \n",
    "    # Ensure the values are within [0, 1]\n",
    "    x_center = min(max(x_center, 0), 1)\n",
    "    y_center = min(max(y_center, 0), 1)\n",
    "    width = min(max(width, 0), 1)\n",
    "    height = min(max(height, 0), 1)\n",
    "    \n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "# Process each label file\n",
    "for filename in os.listdir(label_folder):\n",
    "    if filename.endswith('.txt'):\n",
    "        label_path = os.path.join(label_folder, filename)\n",
    "        image_path = os.path.join(image_folder, filename.replace('.txt', '.jpg'))  # Assuming image is a .jpg file\n",
    "\n",
    "        # Open image to get dimensions\n",
    "        with Image.open(image_path) as img:\n",
    "            img_width, img_height = img.size\n",
    "\n",
    "        # Read label file and convert each line\n",
    "        with open(label_path, 'r') as infile, open(os.path.join(output_folder, filename), 'w') as outfile:\n",
    "            for line in infile:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) > 4:\n",
    "                    # Join the class name parts\n",
    "                    class_name = ' '.join(parts[:-4])\n",
    "                    xmin, ymin, xmax, ymax = map(float, parts[-4:])\n",
    "                    x_center, y_center, width, height = convert_to_yolo(xmin, ymin, xmax, ymax, img_width, img_height)\n",
    "                    # Write to output file in YOLO format with class_id = 0 for all classes\n",
    "                    outfile.write(f\"3 {x_center} {y_center} {width} {height}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e558391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.25 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.24  Python-3.11.1 torch-2.3.0+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=tr.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Subhash\\FOSTRIDE\\datasetss\\labels\\train.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Subhash\\FOSTRIDE\\datasetss\\labels\\train.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G        3.5      3.511      4.204         24        640: 100%|██████████| 32/32 [14:50<00:00, 27.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [05:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250    0.00423      0.457     0.0146    0.00389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G      3.273       3.33      3.915         19        640: 100%|██████████| 32/32 [14:12<00:00, 26.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [03:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250    0.00402      0.439    0.00874    0.00238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G       3.23      3.253      3.656         19        640: 100%|██████████| 32/32 [08:18<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [02:58"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250    0.00736      0.304    0.00924    0.00268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G       3.07      3.186      3.478         18        640: 100%|██████████| 32/32 [07:56<00:00, 14.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [03:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250     0.0537      0.102     0.0266    0.00808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G      2.964      3.173       3.36         24        640: 100%|██████████| 32/32 [09:04<00:00, 17.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [03:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250     0.0541       0.12     0.0269    0.00834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G      3.024      3.174      3.313         21        640: 100%|██████████| 32/32 [09:35<00:00, 17.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [03:48"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250     0.0909      0.191     0.0414     0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G       2.83      3.042      3.201         17        640: 100%|██████████| 32/32 [09:30<00:00, 17.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [05:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.144      0.166     0.0647     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G      2.747      2.951        3.1         24        640: 100%|██████████| 32/32 [14:34<00:00, 27.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [05:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.188      0.146     0.0765     0.0243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G      2.701      2.909      3.041         20        640: 100%|██████████| 32/32 [14:38<00:00, 27.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [05:51"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.182      0.189     0.0931     0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      2.544      2.771      2.945          9        640: 100%|██████████| 32/32 [13:33<00:00, 25.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [02:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.156      0.188     0.0902     0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G      2.487       2.98      2.888          7        640: 100%|██████████| 32/32 [07:31<00:00, 14.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [02:58"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.274      0.249      0.166     0.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G      2.391       2.77      2.832         33        640: 100%|██████████| 32/32 [07:30<00:00, 14.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [03:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250        0.3       0.27      0.177     0.0675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G      2.336      2.708      2.764         40        640: 100%|██████████| 32/32 [07:18<00:00, 13.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [02:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.325      0.266      0.207     0.0942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G      2.206      2.586      2.713          5        640: 100%|██████████| 32/32 [07:29<00:00, 14.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [02:58"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250       0.32      0.261      0.202     0.0922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G      2.101      2.504      2.643          6        640: 100%|██████████| 32/32 [07:23<00:00, 13.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [02:53"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.384      0.285      0.239      0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G      2.019      2.415      2.548          5        640: 100%|██████████| 32/32 [07:16<00:00, 13.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [02:52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250       0.47      0.308      0.303      0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G      1.995      2.396       2.53          4        640: 100%|██████████| 32/32 [07:18<00:00, 13.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [02:53"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.442      0.326      0.308      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G      1.958       2.33       2.47          5        640: 100%|██████████| 32/32 [07:31<00:00, 14.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [03:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.493      0.305      0.331      0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G      1.921      2.302      2.459          5        640: 100%|██████████| 32/32 [07:22<00:00, 13.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [02:59"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.495      0.345      0.352      0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         0G      1.941      2.269      2.443          5        640: 100%|██████████| 32/32 [07:56<00:00, 14.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [03:11"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.498      0.342      0.358      0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 4.412 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.24  Python-3.11.1 torch-2.3.0+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [02:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       1250      0.497      0.344      0.358      0.209\n",
      "Speed: 4.2ms preprocess, 263.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#to train model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model=YOLO(\"yolov8n.yaml\")\n",
    "\n",
    "result=model.train(data=\"tr.yaml\",epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7f5f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 Tires, 443.2ms\n",
      "Speed: 10.6ms preprocess, 443.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results: [ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'Tin_can', 1: 'Plastic_bag', 2: 'Tire', 3: 'Bottle'}\n",
      "obb: None\n",
      "orig_img: array([[[240, 229, 201],\n",
      "        [240, 229, 201],\n",
      "        [241, 230, 202],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[240, 229, 201],\n",
      "        [239, 228, 200],\n",
      "        [239, 228, 200],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[241, 230, 202],\n",
      "        [238, 227, 199],\n",
      "        [237, 226, 198],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[149, 156, 151],\n",
      "        [114, 121, 116],\n",
      "        [113, 120, 115],\n",
      "        ...,\n",
      "        [ 67, 231, 254],\n",
      "        [ 50, 210, 234],\n",
      "        [ 36, 193, 219]],\n",
      "\n",
      "       [[177, 186, 189],\n",
      "        [143, 152, 155],\n",
      "        [144, 153, 156],\n",
      "        ...,\n",
      "        [ 60, 222, 247],\n",
      "        [ 39, 198, 224],\n",
      "        [ 26, 182, 211]],\n",
      "\n",
      "       [[137, 149, 159],\n",
      "        [119, 131, 141],\n",
      "        [135, 147, 153],\n",
      "        ...,\n",
      "        [ 55, 212, 238],\n",
      "        [ 35, 188, 219],\n",
      "        [ 26, 177, 211]]], dtype=uint8)\n",
      "orig_shape: (766, 1024)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 10.60938835144043, 'inference': 443.2029724121094, 'postprocess': 0.0}]\n",
      "Bounding Box: (567.2957153320312, 93.11494445800781), (996.9786987304688, 592.4744262695312), Score: 0.895855188369751, Class ID: 2.0\n",
      "Bounding Box: (587.85986328125, 179.1445770263672), (916.2887573242188, 593.9990234375), Score: 0.25985783338546753, Class ID: 2.0\n",
      "Output image saved at: C:\\Users\\Subhash\\FOSTRIDE/tire_out.jpg\n"
     ]
    }
   ],
   "source": [
    "#for image detection\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define paths\n",
    "MODEL_PATH = os.path.join(r'C:\\Users\\Subhash\\FOSTRIDE\\best.pt')\n",
    "IMAGE_PATH = os.path.join(r'C:\\Users\\Subhash\\FOSTRIDE/tire.jpg')\n",
    "OUTPUT_IMAGE_PATH = '{}_out.jpg'.format(os.path.splitext(IMAGE_PATH)[0])\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# Set a lower threshold\n",
    "threshold = 0.1\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(IMAGE_PATH)\n",
    "H, W, _ = image.shape\n",
    "\n",
    "# Perform object detection\n",
    "results = model(image)\n",
    "\n",
    "# Check results structure and print for debugging\n",
    "print(\"Results:\", results)\n",
    "\n",
    "# Draw bounding boxes and labels\n",
    "if len(results[0].boxes) == 0:\n",
    "    print(\"No detections found.\")\n",
    "else:\n",
    "    for result in results[0].boxes:\n",
    "        # Extract bounding box coordinates, confidence score, and class ID\n",
    "        x1, y1, x2, y2 = result.xyxy[0]\n",
    "        score = result.conf[0]\n",
    "        class_id = result.cls[0]\n",
    "\n",
    "        print(f\"Bounding Box: ({x1}, {y1}), ({x2}, {y2}), Score: {score}, Class ID: {class_id}\")\n",
    "\n",
    "        if score > threshold:\n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            # Put class name text\n",
    "            class_name = model.names[int(class_id)]\n",
    "            cv2.putText(image, class_name.upper(), (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "# Save output image\n",
    "cv2.imwrite(OUTPUT_IMAGE_PATH, image)\n",
    "\n",
    "print(\"Output image saved at:\", OUTPUT_IMAGE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2537f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 Tires, 302.9ms\n",
      "Speed: 14.2ms preprocess, 302.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 287.5ms\n",
      "Speed: 6.2ms preprocess, 287.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 283.2ms\n",
      "Speed: 0.0ms preprocess, 283.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.1ms\n",
      "Speed: 0.0ms preprocess, 271.1ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 285.2ms\n",
      "Speed: 0.0ms preprocess, 285.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 277.3ms\n",
      "Speed: 2.2ms preprocess, 277.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 282.6ms\n",
      "Speed: 0.3ms preprocess, 282.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 299.8ms\n",
      "Speed: 4.0ms preprocess, 299.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 274.5ms\n",
      "Speed: 5.6ms preprocess, 274.5ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 279.0ms\n",
      "Speed: 0.0ms preprocess, 279.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 296.4ms\n",
      "Speed: 3.6ms preprocess, 296.4ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 295.6ms\n",
      "Speed: 0.0ms preprocess, 295.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 275.0ms\n",
      "Speed: 2.3ms preprocess, 275.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 280.2ms\n",
      "Speed: 10.0ms preprocess, 280.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.2ms\n",
      "Speed: 9.3ms preprocess, 271.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 300.6ms\n",
      "Speed: 3.4ms preprocess, 300.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 274.4ms\n",
      "Speed: 8.7ms preprocess, 274.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 284.4ms\n",
      "Speed: 0.0ms preprocess, 284.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 295.2ms\n",
      "Speed: 0.0ms preprocess, 295.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 315.7ms\n",
      "Speed: 4.3ms preprocess, 315.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 296.3ms\n",
      "Speed: 0.0ms preprocess, 296.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 292.5ms\n",
      "Speed: 9.7ms preprocess, 292.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 285.8ms\n",
      "Speed: 4.4ms preprocess, 285.8ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 284.7ms\n",
      "Speed: 3.1ms preprocess, 284.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 308.8ms\n",
      "Speed: 0.0ms preprocess, 308.8ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 288.5ms\n",
      "Speed: 16.8ms preprocess, 288.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 285.4ms\n",
      "Speed: 0.0ms preprocess, 285.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 308.0ms\n",
      "Speed: 0.0ms preprocess, 308.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 278.7ms\n",
      "Speed: 0.0ms preprocess, 278.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 284.1ms\n",
      "Speed: 0.0ms preprocess, 284.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 283.2ms\n",
      "Speed: 15.6ms preprocess, 283.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 282.9ms\n",
      "Speed: 15.6ms preprocess, 282.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.5ms\n",
      "Speed: 0.0ms preprocess, 281.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 296.1ms\n",
      "Speed: 0.0ms preprocess, 296.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 282.2ms\n",
      "Speed: 0.0ms preprocess, 282.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.6ms\n",
      "Speed: 0.0ms preprocess, 281.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 283.3ms\n",
      "Speed: 0.0ms preprocess, 283.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 280.9ms\n",
      "Speed: 0.0ms preprocess, 280.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 280.9ms\n",
      "Speed: 7.8ms preprocess, 280.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 282.5ms\n",
      "Speed: 0.0ms preprocess, 282.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.7ms\n",
      "Speed: 0.0ms preprocess, 281.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 270.8ms\n",
      "Speed: 0.0ms preprocess, 270.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 270.9ms\n",
      "Speed: 0.0ms preprocess, 270.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 287.5ms\n",
      "Speed: 0.0ms preprocess, 287.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 272.3ms\n",
      "Speed: 0.0ms preprocess, 272.3ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 287.6ms\n",
      "Speed: 0.0ms preprocess, 287.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 272.2ms\n",
      "Speed: 0.0ms preprocess, 272.2ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 289.2ms\n",
      "Speed: 0.0ms preprocess, 289.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 257.9ms\n",
      "Speed: 0.0ms preprocess, 257.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.3ms\n",
      "Speed: 0.3ms preprocess, 281.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 282.1ms\n",
      "Speed: 0.0ms preprocess, 282.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 297.6ms\n",
      "Speed: 0.0ms preprocess, 297.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 299.0ms\n",
      "Speed: 0.0ms preprocess, 299.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 282.9ms\n",
      "Speed: 0.0ms preprocess, 282.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 270.7ms\n",
      "Speed: 10.0ms preprocess, 270.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.6ms\n",
      "Speed: 0.0ms preprocess, 281.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.8ms\n",
      "Speed: 0.0ms preprocess, 281.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 289.7ms\n",
      "Speed: 10.0ms preprocess, 289.7ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 282.0ms\n",
      "Speed: 15.6ms preprocess, 282.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.4ms\n",
      "Speed: 0.0ms preprocess, 281.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 272.8ms\n",
      "Speed: 8.2ms preprocess, 272.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 296.6ms\n",
      "Speed: 0.0ms preprocess, 296.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.5ms\n",
      "Speed: 15.7ms preprocess, 271.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 296.9ms\n",
      "Speed: 0.0ms preprocess, 296.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 272.4ms\n",
      "Speed: 15.6ms preprocess, 272.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Tire, 281.1ms\n",
      "Speed: 0.0ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 265.5ms\n",
      "Speed: 0.0ms preprocess, 265.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.3ms\n",
      "Speed: 15.8ms preprocess, 281.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 255.3ms\n",
      "Speed: 0.0ms preprocess, 255.3ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.7ms\n",
      "Speed: 15.6ms preprocess, 271.7ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.1ms\n",
      "Speed: 15.6ms preprocess, 271.1ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.1ms\n",
      "Speed: 15.7ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 270.6ms\n",
      "Speed: 0.0ms preprocess, 270.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.5ms\n",
      "Speed: 9.5ms preprocess, 271.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.2ms\n",
      "Speed: 0.0ms preprocess, 271.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.9ms\n",
      "Speed: 10.0ms preprocess, 271.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.9ms\n",
      "Speed: 10.0ms preprocess, 271.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.9ms\n",
      "Speed: 0.0ms preprocess, 281.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.0ms\n",
      "Speed: 0.0ms preprocess, 281.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 272.5ms\n",
      "Speed: 0.0ms preprocess, 272.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 297.3ms\n",
      "Speed: 0.0ms preprocess, 297.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 282.6ms\n",
      "Speed: 0.7ms preprocess, 282.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 283.9ms\n",
      "Speed: 0.0ms preprocess, 283.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 297.6ms\n",
      "Speed: 0.0ms preprocess, 297.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 280.1ms\n",
      "Speed: 0.0ms preprocess, 280.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.2ms\n",
      "Speed: 0.0ms preprocess, 271.2ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 286.1ms\n",
      "Speed: 0.0ms preprocess, 286.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 287.5ms\n",
      "Speed: 0.0ms preprocess, 287.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 296.7ms\n",
      "Speed: 0.0ms preprocess, 296.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.2ms\n",
      "Speed: 0.0ms preprocess, 271.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 270.9ms\n",
      "Speed: 10.0ms preprocess, 270.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 297.8ms\n",
      "Speed: 0.0ms preprocess, 297.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 1 Tire, 271.7ms\n",
      "Speed: 0.0ms preprocess, 271.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 265.4ms\n",
      "Speed: 15.8ms preprocess, 265.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.8ms\n",
      "Speed: 0.0ms preprocess, 281.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 283.4ms\n",
      "Speed: 0.0ms preprocess, 283.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 267.0ms\n",
      "Speed: 0.0ms preprocess, 267.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 286.6ms\n",
      "Speed: 15.9ms preprocess, 286.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 272.3ms\n",
      "Speed: 0.0ms preprocess, 272.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 265.5ms\n",
      "Speed: 0.0ms preprocess, 265.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 282.7ms\n",
      "Speed: 0.0ms preprocess, 282.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 297.1ms\n",
      "Speed: 0.0ms preprocess, 297.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.8ms\n",
      "Speed: 0.0ms preprocess, 281.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 1 Plastic_bag, 281.7ms\n",
      "Speed: 15.9ms preprocess, 281.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Plastic_bag, 296.9ms\n",
      "Speed: 0.0ms preprocess, 296.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Plastic_bag, 266.0ms\n",
      "Speed: 0.0ms preprocess, 266.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Plastic_bag, 280.7ms\n",
      "Speed: 0.0ms preprocess, 280.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 297.5ms\n",
      "Speed: 0.0ms preprocess, 297.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 271.7ms\n",
      "Speed: 10.0ms preprocess, 271.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 280.7ms\n",
      "Speed: 0.0ms preprocess, 280.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.1ms\n",
      "Speed: 0.0ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.5ms\n",
      "Speed: 0.0ms preprocess, 281.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.9ms\n",
      "Speed: 0.0ms preprocess, 281.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 282.0ms\n",
      "Speed: 0.0ms preprocess, 282.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 297.9ms\n",
      "Speed: 0.0ms preprocess, 297.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 1 Tire, 281.8ms\n",
      "Speed: 0.0ms preprocess, 281.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 280.7ms\n",
      "Speed: 0.0ms preprocess, 280.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 296.3ms\n",
      "Speed: 0.0ms preprocess, 296.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tin_can, 283.8ms\n",
      "Speed: 0.0ms preprocess, 283.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tin_can, 281.7ms\n",
      "Speed: 0.0ms preprocess, 281.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tin_can, 282.0ms\n",
      "Speed: 0.0ms preprocess, 282.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tin_can, 281.1ms\n",
      "Speed: 15.9ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tin_can, 281.6ms\n",
      "Speed: 0.0ms preprocess, 281.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tin_can, 297.0ms\n",
      "Speed: 0.0ms preprocess, 297.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tin_can, 280.7ms\n",
      "Speed: 0.0ms preprocess, 280.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tin_can, 280.3ms\n",
      "Speed: 0.0ms preprocess, 280.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Tin_can, 271.2ms\n",
      "Speed: 0.0ms preprocess, 271.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 313.3ms\n",
      "Speed: 0.0ms preprocess, 313.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 287.3ms\n",
      "Speed: 0.0ms preprocess, 287.3ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 280.9ms\n",
      "Speed: 15.7ms preprocess, 280.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 286.8ms\n",
      "Speed: 0.0ms preprocess, 286.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 287.2ms\n",
      "Speed: 0.0ms preprocess, 287.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.7ms\n",
      "Speed: 0.0ms preprocess, 281.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.0ms\n",
      "Speed: 0.0ms preprocess, 281.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 266.3ms\n",
      "Speed: 0.0ms preprocess, 266.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 298.5ms\n",
      "Speed: 0.0ms preprocess, 298.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 290.4ms\n",
      "Speed: 0.0ms preprocess, 290.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.8ms\n",
      "Speed: 0.0ms preprocess, 281.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.0ms\n",
      "Speed: 0.0ms preprocess, 281.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 265.6ms\n",
      "Speed: 15.9ms preprocess, 265.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.2ms\n",
      "Speed: 0.0ms preprocess, 281.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 282.9ms\n",
      "Speed: 0.0ms preprocess, 282.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 282.4ms\n",
      "Speed: 0.0ms preprocess, 282.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.9ms\n",
      "Speed: 0.0ms preprocess, 281.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 270.9ms\n",
      "Speed: 16.3ms preprocess, 270.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 272.9ms\n",
      "Speed: 0.0ms preprocess, 272.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 273.6ms\n",
      "Speed: 1.6ms preprocess, 273.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 272.3ms\n",
      "Speed: 0.0ms preprocess, 272.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 286.7ms\n",
      "Speed: 0.0ms preprocess, 286.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 273.6ms\n",
      "Speed: 0.0ms preprocess, 273.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 283.0ms\n",
      "Speed: 0.0ms preprocess, 283.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.7ms\n",
      "Speed: 15.8ms preprocess, 281.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 282.6ms\n",
      "Speed: 0.0ms preprocess, 282.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 281.6ms\n",
      "Speed: 16.2ms preprocess, 281.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 265.9ms\n",
      "Speed: 15.8ms preprocess, 265.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 282.0ms\n",
      "Speed: 0.0ms preprocess, 282.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 272.1ms\n",
      "Speed: 0.0ms preprocess, 272.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 287.4ms\n",
      "Speed: 0.0ms preprocess, 287.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 270.2ms\n",
      "Speed: 0.0ms preprocess, 270.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 266.2ms\n",
      "Speed: 15.6ms preprocess, 266.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 1 Tire, 256.2ms\n",
      "Speed: 0.0ms preprocess, 256.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 264.3ms\n",
      "Speed: 0.0ms preprocess, 264.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 270.1ms\n",
      "Speed: 15.8ms preprocess, 270.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 280.8ms\n",
      "Speed: 0.0ms preprocess, 280.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 272.1ms\n",
      "Speed: 0.0ms preprocess, 272.1ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 272.8ms\n",
      "Speed: 15.7ms preprocess, 272.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.1ms\n",
      "Speed: 0.0ms preprocess, 271.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.1ms\n",
      "Speed: 0.0ms preprocess, 271.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 265.3ms\n",
      "Speed: 15.7ms preprocess, 265.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.6ms\n",
      "Speed: 15.8ms preprocess, 281.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 297.2ms\n",
      "Speed: 0.0ms preprocess, 297.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 286.6ms\n",
      "Speed: 0.0ms preprocess, 286.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 287.1ms\n",
      "Speed: 0.0ms preprocess, 287.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 265.2ms\n",
      "Speed: 0.0ms preprocess, 265.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 265.8ms\n",
      "Speed: 0.0ms preprocess, 265.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.6ms\n",
      "Speed: 15.6ms preprocess, 271.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 286.2ms\n",
      "Speed: 0.0ms preprocess, 286.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 274.2ms\n",
      "Speed: 15.7ms preprocess, 274.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.8ms\n",
      "Speed: 0.0ms preprocess, 271.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.2ms\n",
      "Speed: 0.0ms preprocess, 271.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.5ms\n",
      "Speed: 10.0ms preprocess, 271.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 297.9ms\n",
      "Speed: 0.0ms preprocess, 297.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 297.3ms\n",
      "Speed: 15.6ms preprocess, 297.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 297.5ms\n",
      "Speed: 0.0ms preprocess, 297.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 301.8ms\n",
      "Speed: 0.0ms preprocess, 301.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 297.5ms\n",
      "Speed: 0.0ms preprocess, 297.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 298.5ms\n",
      "Speed: 15.6ms preprocess, 298.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 297.0ms\n",
      "Speed: 16.3ms preprocess, 297.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 271.0ms\n",
      "Speed: 0.0ms preprocess, 271.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 302.8ms\n",
      "Speed: 0.0ms preprocess, 302.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 283.4ms\n",
      "Speed: 16.1ms preprocess, 283.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 1 Tire, 281.3ms\n",
      "Speed: 0.0ms preprocess, 281.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 281.1ms\n",
      "Speed: 0.0ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 342.6ms\n",
      "Speed: 0.0ms preprocess, 342.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 1 Tire, 288.1ms\n",
      "Speed: 0.0ms preprocess, 288.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 275.1ms\n",
      "Speed: 0.0ms preprocess, 275.1ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 (no detections), 287.5ms\n",
      "Speed: 0.0ms preprocess, 287.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No detections found.\n",
      "\n",
      "0: 384x640 1 Tire, 298.6ms\n",
      "Speed: 0.0ms preprocess, 298.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 280.9ms\n",
      "Speed: 0.0ms preprocess, 280.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 272.2ms\n",
      "Speed: 0.0ms preprocess, 272.2ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 287.5ms\n",
      "Speed: 0.0ms preprocess, 287.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 288.0ms\n",
      "Speed: 0.0ms preprocess, 288.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 287.1ms\n",
      "Speed: 0.0ms preprocess, 287.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.0ms\n",
      "Speed: 0.0ms preprocess, 271.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 280.7ms\n",
      "Speed: 0.0ms preprocess, 280.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 280.7ms\n",
      "Speed: 0.0ms preprocess, 280.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.6ms\n",
      "Speed: 0.0ms preprocess, 281.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.3ms\n",
      "Speed: 0.0ms preprocess, 281.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.6ms\n",
      "Speed: 0.0ms preprocess, 281.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.4ms\n",
      "Speed: 0.0ms preprocess, 281.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 298.2ms\n",
      "Speed: 0.0ms preprocess, 298.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 280.9ms\n",
      "Speed: 0.0ms preprocess, 280.9ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 265.5ms\n",
      "Speed: 15.8ms preprocess, 265.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.9ms\n",
      "Speed: 0.0ms preprocess, 281.9ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 274.1ms\n",
      "Speed: 15.8ms preprocess, 274.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 292.8ms\n",
      "Speed: 0.0ms preprocess, 292.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 264.7ms\n",
      "Speed: 15.9ms preprocess, 264.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 283.0ms\n",
      "Speed: 0.0ms preprocess, 283.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.0ms\n",
      "Speed: 0.0ms preprocess, 281.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.1ms\n",
      "Speed: 0.0ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 281.1ms\n",
      "Speed: 0.0ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.6ms\n",
      "Speed: 15.6ms preprocess, 271.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 288.2ms\n",
      "Speed: 0.0ms preprocess, 288.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 287.5ms\n",
      "Speed: 0.0ms preprocess, 287.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.4ms\n",
      "Speed: 0.0ms preprocess, 271.4ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.2ms\n",
      "Speed: 0.0ms preprocess, 271.2ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 285.5ms\n",
      "Speed: 0.0ms preprocess, 285.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 287.6ms\n",
      "Speed: 0.0ms preprocess, 287.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 286.5ms\n",
      "Speed: 0.0ms preprocess, 286.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 287.0ms\n",
      "Speed: 0.0ms preprocess, 287.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.4ms\n",
      "Speed: 15.6ms preprocess, 271.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.3ms\n",
      "Speed: 0.0ms preprocess, 271.3ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 286.8ms\n",
      "Speed: 0.0ms preprocess, 286.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 282.5ms\n",
      "Speed: 0.0ms preprocess, 282.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 270.6ms\n",
      "Speed: 0.0ms preprocess, 270.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 271.4ms\n",
      "Speed: 10.0ms preprocess, 271.4ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 272.0ms\n",
      "Speed: 0.0ms preprocess, 272.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 272.0ms\n",
      "Speed: 10.0ms preprocess, 272.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 287.9ms\n",
      "Speed: 0.0ms preprocess, 287.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 286.8ms\n",
      "Speed: 0.0ms preprocess, 286.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 272.4ms\n",
      "Speed: 10.0ms preprocess, 272.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 274.1ms\n",
      "Speed: 9.8ms preprocess, 274.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 270.8ms\n",
      "Speed: 0.0ms preprocess, 270.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 286.7ms\n",
      "Speed: 10.0ms preprocess, 286.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 287.5ms\n",
      "Speed: 0.0ms preprocess, 287.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 Tires, 303.6ms\n",
      "Speed: 0.0ms preprocess, 303.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.5ms\n",
      "Speed: 15.6ms preprocess, 271.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 297.7ms\n",
      "Speed: 0.0ms preprocess, 297.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 290.3ms\n",
      "Speed: 0.0ms preprocess, 290.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.7ms\n",
      "Speed: 0.0ms preprocess, 281.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.7ms\n",
      "Speed: 0.0ms preprocess, 281.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 286.6ms\n",
      "Speed: 0.0ms preprocess, 286.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 287.3ms\n",
      "Speed: 0.0ms preprocess, 287.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 296.3ms\n",
      "Speed: 0.0ms preprocess, 296.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.8ms\n",
      "Speed: 15.6ms preprocess, 271.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 286.3ms\n",
      "Speed: 0.0ms preprocess, 286.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 282.7ms\n",
      "Speed: 15.6ms preprocess, 282.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 270.5ms\n",
      "Speed: 1.2ms preprocess, 270.5ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 287.2ms\n",
      "Speed: 0.0ms preprocess, 287.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 287.6ms\n",
      "Speed: 0.0ms preprocess, 287.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 286.8ms\n",
      "Speed: 0.0ms preprocess, 286.8ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 281.1ms\n",
      "Speed: 16.1ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 272.3ms\n",
      "Speed: 0.0ms preprocess, 272.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 270.6ms\n",
      "Speed: 15.6ms preprocess, 270.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 271.3ms\n",
      "Speed: 10.0ms preprocess, 271.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 281.3ms\n",
      "Speed: 0.0ms preprocess, 281.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 281.5ms\n",
      "Speed: 0.0ms preprocess, 281.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 270.8ms\n",
      "Speed: 10.0ms preprocess, 270.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 266.9ms\n",
      "Speed: 0.0ms preprocess, 266.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.9ms\n",
      "Speed: 0.0ms preprocess, 281.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.5ms\n",
      "Speed: 0.0ms preprocess, 281.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.4ms\n",
      "Speed: 0.0ms preprocess, 281.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.4ms\n",
      "Speed: 0.0ms preprocess, 281.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.5ms\n",
      "Speed: 0.0ms preprocess, 271.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 270.9ms\n",
      "Speed: 10.0ms preprocess, 270.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.7ms\n",
      "Speed: 10.1ms preprocess, 271.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 266.1ms\n",
      "Speed: 16.2ms preprocess, 266.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 265.4ms\n",
      "Speed: 15.6ms preprocess, 265.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 281.0ms\n",
      "Speed: 0.0ms preprocess, 281.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 280.9ms\n",
      "Speed: 0.0ms preprocess, 280.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 296.8ms\n",
      "Speed: 0.0ms preprocess, 296.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 265.8ms\n",
      "Speed: 0.0ms preprocess, 265.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 270.7ms\n",
      "Speed: 15.7ms preprocess, 270.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 291.6ms\n",
      "Speed: 0.0ms preprocess, 291.6ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.8ms\n",
      "Speed: 16.1ms preprocess, 271.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 270.4ms\n",
      "Speed: 0.0ms preprocess, 270.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.4ms\n",
      "Speed: 10.0ms preprocess, 271.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 287.7ms\n",
      "Speed: 0.0ms preprocess, 287.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 276.3ms\n",
      "Speed: 0.0ms preprocess, 276.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.4ms\n",
      "Speed: 0.0ms preprocess, 281.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.7ms\n",
      "Speed: 0.0ms preprocess, 281.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 265.5ms\n",
      "Speed: 0.5ms preprocess, 265.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 264.7ms\n",
      "Speed: 15.9ms preprocess, 264.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.0ms\n",
      "Speed: 0.0ms preprocess, 281.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.7ms\n",
      "Speed: 15.7ms preprocess, 271.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.4ms\n",
      "Speed: 15.6ms preprocess, 271.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 271.2ms\n",
      "Speed: 15.7ms preprocess, 271.2ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 281.4ms\n",
      "Speed: 15.7ms preprocess, 281.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 287.7ms\n",
      "Speed: 0.0ms preprocess, 287.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 286.6ms\n",
      "Speed: 0.0ms preprocess, 286.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 283.5ms\n",
      "Speed: 15.6ms preprocess, 283.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 276.4ms\n",
      "Speed: 0.0ms preprocess, 276.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 269.6ms\n",
      "Speed: 15.6ms preprocess, 269.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 274.6ms\n",
      "Speed: 15.6ms preprocess, 274.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 197.3ms\n",
      "Speed: 0.0ms preprocess, 197.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 155.8ms\n",
      "Speed: 0.0ms preprocess, 155.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 187.3ms\n",
      "Speed: 0.0ms preprocess, 187.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 171.1ms\n",
      "Speed: 0.0ms preprocess, 171.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 171.0ms\n",
      "Speed: 0.0ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 171.0ms\n",
      "Speed: 0.0ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 Tires, 139.9ms\n",
      "Speed: 0.0ms preprocess, 139.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 232.1ms\n",
      "Speed: 0.0ms preprocess, 232.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 188.2ms\n",
      "Speed: 0.0ms preprocess, 188.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 154.4ms\n",
      "Speed: 3.1ms preprocess, 154.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 179.5ms\n",
      "Speed: 0.0ms preprocess, 179.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 300.3ms\n",
      "Speed: 0.0ms preprocess, 300.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 285.5ms\n",
      "Speed: 0.0ms preprocess, 285.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 273.5ms\n",
      "Speed: 10.4ms preprocess, 273.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 290.3ms\n",
      "Speed: 10.0ms preprocess, 290.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 302.3ms\n",
      "Speed: 8.5ms preprocess, 302.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 294.2ms\n",
      "Speed: 0.0ms preprocess, 294.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 284.9ms\n",
      "Speed: 0.0ms preprocess, 284.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 291.4ms\n",
      "Speed: 0.0ms preprocess, 291.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 305.7ms\n",
      "Speed: 4.2ms preprocess, 305.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Tire, 283.9ms\n",
      "Speed: 0.0ms preprocess, 283.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 295.2ms\n",
      "Speed: 0.0ms preprocess, 295.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 280.5ms\n",
      "Speed: 2.1ms preprocess, 280.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 280.1ms\n",
      "Speed: 10.4ms preprocess, 280.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 281.9ms\n",
      "Speed: 0.0ms preprocess, 281.9ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 309.2ms\n",
      "Speed: 0.0ms preprocess, 309.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 289.5ms\n",
      "Speed: 1.8ms preprocess, 289.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 285.7ms\n",
      "Speed: 0.0ms preprocess, 285.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 299.1ms\n",
      "Speed: 0.0ms preprocess, 299.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 290.9ms\n",
      "Speed: 10.2ms preprocess, 290.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 284.8ms\n",
      "Speed: 0.0ms preprocess, 284.8ms inference, 0.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 288.7ms\n",
      "Speed: 10.0ms preprocess, 288.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 309.5ms\n",
      "Speed: 0.0ms preprocess, 309.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 289.7ms\n",
      "Speed: 8.1ms preprocess, 289.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 287.7ms\n",
      "Speed: 8.2ms preprocess, 287.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 294.0ms\n",
      "Speed: 0.0ms preprocess, 294.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 299.5ms\n",
      "Speed: 0.0ms preprocess, 299.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 287.5ms\n",
      "Speed: 10.4ms preprocess, 287.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 285.4ms\n",
      "Speed: 0.0ms preprocess, 285.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 285.4ms\n",
      "Speed: 0.0ms preprocess, 285.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 285.5ms\n",
      "Speed: 0.0ms preprocess, 285.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 286.6ms\n",
      "Speed: 0.0ms preprocess, 286.6ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 272.2ms\n",
      "Speed: 15.8ms preprocess, 272.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 330.2ms\n",
      "Speed: 0.0ms preprocess, 330.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Tires, 294.8ms\n",
      "Speed: 0.0ms preprocess, 294.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Tires, 285.6ms\n",
      "Speed: 0.0ms preprocess, 285.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Output video saved at: C:\\Users\\Subhash\\FOSTRIDE\\testing\\tir_out.mp4\n"
     ]
    }
   ],
   "source": [
    "#for video detection\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define paths\n",
    "MODEL_PATH = os.path.join(r'C:\\Users\\Subhash\\FOSTRIDE\\best.pt')\n",
    "VIDEO_PATH = os.path.join(r'C:\\Users\\Subhash\\FOSTRIDE\\testing\\tir.mp4')\n",
    "OUTPUT_VIDEO_PATH = '{}_out.mp4'.format(os.path.splitext(VIDEO_PATH)[0])\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# Set thresholds\n",
    "general_threshold = 0.1\n",
    "tire_threshold = 0.1 # Adjust this value as needed\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    if len(results[0].boxes) == 0:\n",
    "        print(\"No detections found.\")\n",
    "    else:\n",
    "        for result in results[0].boxes:\n",
    "            # Extract bounding box coordinates, confidence score, and class ID\n",
    "            x1, y1, x2, y2 = result.xyxy[0]\n",
    "            score = result.conf[0]\n",
    "            class_id = result.cls[0]\n",
    "\n",
    "            # Get the class name\n",
    "            class_name = model.names[int(class_id)]\n",
    "\n",
    "            # Apply the threshold based on class name\n",
    "            if class_name == 'Tire':\n",
    "                if score > tire_threshold:\n",
    "                    # Draw rectangle\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                    # Put class name text\n",
    "                    cv2.putText(frame, class_name.upper(), (int(x1), int(y1 - 10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                if score > general_threshold:\n",
    "                    # Draw rectangle\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                    # Put class name text\n",
    "                    cv2.putText(frame, class_name.upper(), (int(x1), int(y1 - 10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Write the frame into the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Optionally, display the frame (comment out if not needed)\n",
    "    # cv2.imshow('Frame', frame)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Output video saved at:\", OUTPUT_VIDEO_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing on live video\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "MODEL_PATH = os.path.join(r'/home/subhash/Downloads/best.pt')\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# Access the external camera (change the index if needed)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video capture.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture image.\")\n",
    "        break\n",
    "\n",
    "    # Perform detection\n",
    "    results = model.predict(source=frame, show=False)\n",
    "\n",
    "    # Draw the results on the frame\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            confidence = box.conf[0]\n",
    "            class_id = box.cls[0]\n",
    "            label = f'{model.names[int(class_id)]}: {confidence:.2f}'\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('YOLOv8 Real-Time Detection', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54fdd29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have corresponding label files.\n"
     ]
    }
   ],
   "source": [
    "# for checking correct dataset\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "images_path = os.path.join(r'C:\\Users\\Subhash\\FOSTRIDE\\kdataset\\images\\train')\n",
    "labels_path = os.path.join(r'C:\\Users\\Subhash\\FOSTRIDE\\kdataset\\labels\\train')\n",
    "\n",
    "# Function to check for missing labels\n",
    "def check_missing_labels(images_path, labels_path):\n",
    "    missing_labels = []\n",
    "    \n",
    "\n",
    "    for filename in os.listdir(images_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Add other image extensions if necessary\n",
    "            label_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "            label_path = os.path.join(labels_path, label_filename)\n",
    "            \n",
    "            if not os.path.exists(label_path):\n",
    "                missing_labels.append(filename)\n",
    "                os.remove(os.path.join(images_path, filename))\n",
    "                \n",
    "    \n",
    "    return missing_labels\n",
    "\n",
    "# Check for missing labels\n",
    "missing_labels = check_missing_labels(images_path, labels_path)\n",
    "\n",
    "# Print results\n",
    "if missing_labels:\n",
    "    print(f\"The following {len(missing_labels)}images do not have corresponding label files:\")\n",
    "    for image in missing_labels:\n",
    "        print(image)\n",
    "else:\n",
    "    print(\"All images have corresponding label files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8735b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
